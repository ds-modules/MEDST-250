{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://ndownloader.figshare.com/files/3686778 -P data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!unzip data/3686778 -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Conversional Novel\n",
    "\n",
    "> The first step was to divide each novel into twenty equal parts. Rather than rely on the\n",
    "irregularity of chapter divisions, which can vary within and between works, this process creates\n",
    "standard units of analysis. [95]\n",
    "\n",
    "Instead of actually using chapter divisions, Piper elects to split each novel into 20 equal parts. We can write a function `text_splitter` that will take in a `str` of the text and return a list of 20 equal parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_splitter(text):\n",
    "    n = int(len(text)/20)  # get length n of each part\n",
    "    text_list = [text[i*n:(i+1)*n] for i in range(20)]  # slice out the text\n",
    "    return(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I then\n",
    "calculated the Euclidean distance between each of the twenty parts of the work based on\n",
    "the frequency of the remaining words and stored those results in a symmetrical distance\n",
    "table. In the end, for each work I had a 20x20 table of distances between every part of\n",
    "a work to every other, in which the distances are considered to be measures of the similarity\n",
    "of the language between a workâ€™s individual parts. [95]\n",
    "\n",
    "Piper then calculates the ***Euclidean*** distances between each part to every other part. So we'll have to calculate the distance and use our `pairwise` method. We can write a function for that too! To make it better, let's have it take in a list of texts that our `text_splitter` will output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_distances(text_list):\n",
    "    \n",
    "    from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "    from sklearn.metrics import pairwise\n",
    "    \n",
    "    ye_olde_stop_words = ['thou','thy','thee', 'thine', 'ye', 'hath','hast', 'wilt','aught',\\\n",
    "                          'art', 'dost','doth', 'shall', 'shalt','tis','canst','thyself',\\\n",
    "                         'didst', 'yea', 'wert']\n",
    "    stop_words = list(ENGLISH_STOP_WORDS)+ye_olde_stop_words\n",
    "    cv = CountVectorizer(stop_words = stop_words, min_df=0.6)\n",
    "    dtm = cv.fit_transform(text_list)\n",
    "    tt = TfidfTransformer(norm='l1',use_idf=False)\n",
    "    dtm_tf = tt.fit_transform(dtm)\n",
    "    dist_matrix = pairwise.pairwise_distances(dtm_tf, metric='euclidean')\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piper the introduces two new ideas.\n",
    "\n",
    "> for the ***in-half distance*** I took the average distance of each part in the first half of a work to every other part in that half and subtracted it from the average distance of every part of the second half to itself. [95]\n",
    "\n",
    "Let's write a function that does that, and have it take in our matrix returned by `text_distances`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_half_dist(matrix):\n",
    "    n = len(matrix)  # length of work, should be 20\n",
    "    d1 = []  # will hold distances for first half\n",
    "    d2 = []  # will hold distances for second half\n",
    "    for i in range(int(n/2)-1):  # loop through first half of work (10 in our case)\n",
    "        for j in range(i+1, int(n/2)):  # loop through itself (first half again)\n",
    "            d1.append(matrix[i,j])  # append distance between one part to another (in first half)\n",
    "    for i in range(int(n/2), n-1):\n",
    "        for j in range(i+1, n):\n",
    "            d2.append(matrix[i,j])\n",
    "    return(abs(sum(d1)-sum(d2))/len(d1))  # take average of each distance array and subtract 2 from 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! And now for his second measure:\n",
    "\n",
    "> For the cross-half distance, I took the average distance between\n",
    "all of the first ten parts of a work to all of the second ten parts of a work, similar to the\n",
    "process used in group average clustering. [95]\n",
    "\n",
    "Let's write another function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_half_dist(matrix):\n",
    "    n = len(matrix)  # number of parts, here 20\n",
    "    d = []  # will hold distnaces\n",
    "    for i in range(int(n/2)):  # loop through first half\n",
    "        for j in range(int(n/2), n):  # loop through second half\n",
    "            d.append(matrix[i,j])  # append distance between first and second\n",
    "    return(sum(d)/len(d))  # take average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can also write ourselves a quick function to call the four functions we just wrote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_measures(text):\n",
    "    text_list = text_splitter(text)\n",
    "    dist_matrix = text_distances(text_list)\n",
    "    return(cross_half_dist(dist_matrix), in_half_dist(dist_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text_measures` should now return two values. The first values is the `cross_half_dist` and the second values is the `in_half_dist`. Let's test this out on Augustine's `Confessions':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/Augustine-Confessions.txt') as f:\n",
    "    confessions = f.read()\n",
    "\n",
    "text_measures(confessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now we can read in the corpus Piper used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "metadata_tb = Table.read_table('data/2_txtlab_Novel450.csv')\n",
    "metadata_tb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll stick with English so we don't have to think about the possible issues of going between languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_tb = metadata_tb.where('language', \"English\")\n",
    "metadata_tb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll slightly change our `text_measures` function so that it can read in the file of the text we want to read in, instead of taking the `confessions` string we already had:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_path = 'data/2_txtalb_Novel450/'\n",
    "\n",
    "def text_measures_alt(text_name):\n",
    "    with open(corpus_path+text_name, 'r') as file_in:\n",
    "        text = file_in.read()\n",
    "    text_list = text_splitter(text)\n",
    "    dist_matrix = text_distances(text_list)\n",
    "    return(cross_half_dist(dist_matrix), in_half_dist(dist_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `Table`'s `apply` method to call the function `text_measures_alt` on all the files in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "measures = metadata_tb.apply(text_measures_alt, 'filename')\n",
    "measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add these measures to our `Table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_tb['Cross-Half'] = measures[:,0]\n",
    "metadata_tb['In-Half'] = measures[:,1]\n",
    "metadata_tb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see which novels stick out, we might be interested in the z-score for a particular novel. This is how many standard devations the novel is away from the mean. Let's write a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_zscores(values):\n",
    "\n",
    "    import numpy as np\n",
    "    mn = np.mean(values)\n",
    "    st = np.std(values)\n",
    "    zs = []\n",
    "    \n",
    "    for x in values:\n",
    "        z = (x-mn)/st\n",
    "        zs.append(z)\n",
    "\n",
    "    return zs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add these to the `Table` too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_tb['Cross-Z-Score'] = get_zscores(measures[:,0])\n",
    "metadata_tb['In-Z-Score'] = get_zscores(measures[:,1])\n",
    "metadata_tb.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter plot, please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metadata_tb.scatter('In-Half', 'Cross-Half')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Use our z-scores to rank the novels. Which novels are most \"conversional\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Piper includes only words that appeared in at least 60% of the book's sections. How might that shape his findings? What if he had used a 50% threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing the `min_df` argument to 0.5. How do the rankings change? Try eliminating the `min_df` altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bonus (not assigned)\n",
    "\n",
    "Visualize distances among the twenty sections of the top-ranked conversional novel in the corpus using the MDS technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
