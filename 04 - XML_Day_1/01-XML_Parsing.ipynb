{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MEDST-250] Text Analysis for Medievalists\n",
    "In this Jupyter notebook, we will look to see how to analyze and parse text from an XML file. We will be looking at a Python module that makes it easy for us to parse through XML files.\n",
    "\n",
    "### Topics Covered\n",
    "- Using `xml` module\n",
    "- Web scraping\n",
    "- Parsing a corpus of XML documents\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section data)<br>\n",
    "\n",
    "\n",
    "1 - [Section 1: Parsing XML using ElementTree](#section 1)<br>\n",
    "\n",
    "2 - [Section 2: Web scraping crash course!](#section 2)<br>\n",
    "\n",
    "2 - [Section 3: Parsing a corpus of XML documents](#section 3)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET  # XML parser\n",
    "import glob  # navigate file system\n",
    "import requests  # make requests to web servers\n",
    "import time  # will help us pause python's for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Data <a id='data'></a>\n",
    "In this notebook, you'll be working with a XML file from Piers Plowman. An XML file is a basic markup of content in a file that gathers and contains a certain amount of material within different tags and subtags. We will be using this XML file to learn in general how to parse XML files of texts. The texts come from http://piers.chass.ncsu.edu/texts.html. From now on, we will be using an example in the data folder called `ppexample.xml` as our test for parsing through. \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Parsing XML File using `ElementTree` Module  <a id='section 1'></a>\n",
    "\n",
    "First we need to import the XML file into an `ElementTree` instance, this basically creates an `ElementTree` format of all this subtags of each tag in the XML file so we can further analyze the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_file = 'data/ppexample.xml'\n",
    "tree = ET.ElementTree(file=xml_file)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about tree file structures, we often want to work from the root into specific nodes. With XML we might want to know the top level, or `root`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = tree.getroot()\n",
    "print(tree.getroot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now we know how to get the root, but it's just an object right now and we can't see much else.\n",
    "\n",
    "We can then find all the child tags in the root and `print` them out so we can view them in the future. An XML file has a root file that has children, and each of these children has a tag and attribute, and maybe some associated text with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for child in root:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not super helpful, but let's start to build out our hierarchical understanding of XML by traversing through the children and building out a path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teiHeader = root.find('teiHeader')\n",
    "for child in teiHeader:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileDesc = root.find('teiHeader/fileDesc')\n",
    "for child in fileDesc:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titleStmt = root.find('teiHeader/fileDesc/titleStmt')\n",
    "for child in titleStmt:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titleStmt = root.find('teiHeader/fileDesc/titleStmt/title')\n",
    "for child in titleStmt:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we may have hit the bottom! Since we've hit a terminal element there's likely text here, so we can just `find` the path and ask for the `.text` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.find('teiHeader/fileDesc/titleStmt/title').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have [this](http://piers.chass.ncsu.edu/texts/F/4?tags=off&view=all) file. Let's take a closer look on that page\n",
    "\n",
    "---\n",
    "\n",
    "We can navigate around these tags now that we have a better visual understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publicationStmt = root.find('teiHeader/fileDesc/publicationStmt')\n",
    "for child in publicationStmt:\n",
    "    print(child.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `itertext` method will generate a `list` of `str`ings from all children:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(publicationStmt.itertext())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just wanted one element, we can ask with the direct path like we did above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.find('teiHeader/fileDesc/publicationStmt/publisher').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the `strip` method can come in handy. We don't need that extra whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root.find('teiHeader/fileDesc/publicationStmt/publisher').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But while we love metadata, we're here for the text!\n",
    "\n",
    "## Challenge\n",
    "\n",
    "Take some time to play with the tags that exists in the `text/` path and try to write some direct paths to pull out the information.\n",
    "\n",
    "***WARNING***: This will be difficult because the text of the tree is highly fragmented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Let's look at another way to iterate through content.\n",
    "\n",
    "We can iterate through all the elements in the XML file by creating an iterator (something that goes through all parts of a file) and iterating through all possible elements/their tags.\n",
    "\n",
    "We'll also print out the `attrib`, which sometimes gives us more information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter_ = tree.getiterator()\n",
    "for elem in iter_:\n",
    "    print(elem.tag, elem.attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see, there are so many tags of certain names. In our tree variable we can then look for specific types of tags such as dates by getting the \"text\" attribute out of each element. We can use conditionals to select what we're interested in:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem in iter_:\n",
    "    if elem.tag == \"date\":\n",
    "        print(elem.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use `itertext()` but make it one string, we can `join` the resulting `list`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem in iter_:\n",
    "    if elem.tag == \"foreign\":\n",
    "        print(elem.attrib)\n",
    "        print(''.join(list(elem.itertext())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem in iter_:\n",
    "    if elem.tag == \"note\":\n",
    "        print(elem.attrib)\n",
    "        print(''.join(list(elem.itertext())))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say we only wanted the `textual` notes and we don't care about the `lexcial` ones, we can run the same code as above but filter out with another conditional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for elem in iter_:\n",
    "    if elem.tag == \"note\" and elem.attrib['type'] == 'textual':\n",
    "        print(''.join(list(elem.itertext())))\n",
    "        print(elem.attrib)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Write some code below that extracts all the corrections from the document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Web scraping crash course! <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we now we know how to parse *1* XML document. But what if we had a whole corpus? Like all of the *passi* from each manuscript? Well [the archive has them](http://piers.chass.ncsu.edu/texts.html)! Unfortunately, that's like over 100 downloads. It'd be great if we could automate that downloading.\n",
    "\n",
    "Guess what? ***WE CAN, YAY***\n",
    "\n",
    "Web scraping, in simple terms, is when you write a script to automate the collection of data from the internet. We have a simple example here because all we need to do is change the URL.\n",
    "\n",
    "Note the [URL for our example above](http://piers.chass.ncsu.edu/texts/F/4/xml):\n",
    "\n",
    "`http://piers.chass.ncsu.edu/texts/F/4/xml`\n",
    "\n",
    "You see the end of that URL? The `F` is just the manuscript name. The `4` is *passus* 4. Since we know *Piers Plowman* has 20 *passi* we can just manipulate that string to download all of the XML files.\n",
    "\n",
    "Let's first focus on just generating all the strings for one manuscript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'http://piers.chass.ncsu.edu/texts/F/1/xml'\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add in one more `for` loop to do this for each manuscript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mss = ['F', 'G', 'Hm', 'L', 'M', 'O', 'R', 'W']\n",
    "\n",
    "## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we actual start scraping, we need to know how `requests` works. The `requests` library will basically get you the response from a web server and can give you the raw text of the website's code. In this case, these URLs return XML code. Let's see how it works with one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests.get('http://piers.chass.ncsu.edu/texts/F/4/xml').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is! Then we can just save that to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xml_data = requests.get('http://piers.chass.ncsu.edu/texts/F/4/xml').text\n",
    "\n",
    "with open('passus_4.xml', 'w') as f:\n",
    "    f.write(xml_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!\n",
    "\n",
    "We can then put it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all manuscript names\n",
    "mss = ['F', 'G', 'Hm', 'L', 'M', 'O', 'R', 'W']\n",
    "\n",
    "# iterate through manuscripts\n",
    "for ms in mss:\n",
    "    \n",
    "    # iterate through passi\n",
    "    for i in range(1,21):\n",
    "        \n",
    "        # build url\n",
    "        url = 'http://piers.chass.ncsu.edu/texts/{}/{}/xml'.format(ms, str(i))\n",
    "        print(url)\n",
    "        \n",
    "        # get the response\n",
    "        res = requests.get(url).text\n",
    "        \n",
    "        #create a file name\n",
    "        fname = 'data/passus/passus-' + ms + '-' + str(i) + '.xml'\n",
    "        \n",
    "        # save the file\n",
    "        with open(fname, 'w') as f:\n",
    "            f.write(res)\n",
    "\n",
    "        # pause for a second so we don't overload their servers\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what we've got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls data/passus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat data/passus/passus-F-1.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Parsing an XML corpus <a id='section 3'></a>\n",
    "\n",
    "Great, now we have a massive corpus! Now we could start comparing across the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to hold our collected data\n",
    "manu_data = {'F': [], \n",
    "             'G': [],\n",
    "             'Hm': [],\n",
    "             'L': [],\n",
    "             'M': [],\n",
    "             'O': [],\n",
    "             'R': [],\n",
    "             'W': []}\n",
    "\n",
    "# iterate through XML files\n",
    "for fname in glob.glob('data/passus/*'):\n",
    "\n",
    "    # get manuscript name and passus number\n",
    "    manuscript = fname.split('-')[1]\n",
    "    passus = fname.split('-')[2].split('.')[0]\n",
    "    \n",
    "    print(fname)\n",
    "    print(manuscript)\n",
    "    print(passus)\n",
    "    print()\n",
    "    \n",
    "    # parse XML file\n",
    "    xml_file = fname\n",
    "    tree = ET.ElementTree(file=xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    print(list(root.find('teiHeader/fileDesc/titleStmt/title').itertext()))\n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('='*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "All work is adapted or taken from:\n",
    "- Driscoll, Mike. (2013, April). Python 101 â€“ Intro to XML Parsing with ElementTree. Retrieved from https://www.blog.pythonlibrary.org/2013/04/30/python-101-intro-to-xml-parsing-with-elementtree/\n",
    "\n",
    "- Driscoll, Mike. (2010, November). Python: Parsing XML with lxml. Retrieved from https://www.blog.pythonlibrary.org/2010/11/20/python-parsing-xml-with-lxml/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Tejas Priyadarshan\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
