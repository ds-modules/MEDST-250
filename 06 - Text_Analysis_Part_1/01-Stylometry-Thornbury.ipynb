{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MEDST-250] Stylometry\n",
    "\n",
    "---\n",
    "<img src=\"http://www.cleargoals.com/wp-content/uploads/2017/04/data-science-methods-and-algorithms-for-big-data.jpg\" style=\"width: 500px; height: 275px;\" />\n",
    "\n",
    "This notebook is designed to reproduce several findings from Emily Thornbury's chapter \"The Poet Alone\" in her book Becoming a Poet in Anglo-Saxon England. In particular, Fig. 4.5 on page 170.\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Python `str` and `list` Basics\n",
    "- Analyzing Text\n",
    "- Basic Visualization\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1 - [Python Lists](#section 1)<br>\n",
    "\n",
    "2 - [List Comprehensions](#section 2)<br>\n",
    "\n",
    "3 - [Word Frequencies](#section 3)<br>\n",
    "\n",
    "4 - [Counting](#section 4) <br>\n",
    "\n",
    "5 - [Ad Hoc Stylometry](#section 5)<br>\n",
    "\n",
    "6 - [Super Challenge: Acrostics](#section 6)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Lists<a id='section 1'></a>\n",
    "\n",
    "First, we're going to learn how to work with Python lists. We've already seen lists in bit in previous lessons. Lists allow us to store words for easier manipulation later on. After all, how else can we count features of a string unless we can somehow make a list of items out of it?\n",
    "\n",
    "Here's an example of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"þæt\", \"wearð\", \"underne\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do I know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type([\"þæt\", \"wearð\", \"underne\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign these to variables too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hemistich = [\"þæt\", \"wearð\", \"underne\"]\n",
    "second_hemistich = [\"eorðbuendum\"]\n",
    "print(first_hemistich)\n",
    "print(second_hemistich)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perform mathematical operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_hemistich + second_hemistich)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assign that to `first_line`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_line = first_hemistich + second_hemistich\n",
    "print(first_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the length of a list using the `len` function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(first_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index into lists with brackets [ ], let's get the first word of the first line:\n",
    "\n",
    "#### NOTE: Python (and many other languages) start counting from 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_line[0]) # returns the first word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_line[1]) # returns the second word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a range of elements using a semi-colon. Querying a range of elements from a list returns another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_line[:2])\n",
    "print(type(first_line[:2])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a small excercise to test your knowledge or python lists.\n",
    "\n",
    "Below are the first three lines of *Christ and Satan* assigned to three `list`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_line = ['þæt', 'wearð', 'underne', 'eorðbuendum,']\n",
    "second_line = ['þæt', 'meotod', 'hæfde', 'miht', 'and', 'strengðo']\n",
    "third_line = ['ða', 'he', 'gefestnade', 'foldan', 'sceatas.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1:\n",
    "Concatenate the first three lines of *Christ and Satan*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2:\n",
    "Retrieve the third element from the combined list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3:\n",
    "Retrieve the fourth through sixth elements from the combined list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4:\n",
    "`print` the number of words in the first three lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List Comprehensions <a id='section 2'></a>\n",
    "\n",
    "List comprehensions allow us to quickly and easily manipulate elements in a list without having to deal with loops. This can also involve removing and inserting items from a list. For example, here's our first line again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subset that to those words containing an \"e\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[word for word in first_line if \"e\" in word] #Using List Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INSTEAD OF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_e = []\n",
    "for word in first_line:\n",
    "    if \"e\" in word:\n",
    "        has_e.append(word)\n",
    "has_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know why list comprehensions are one of the best parts of Python!\n",
    "In relation to text analysis, list comprehensions will come in handy when we want to parse and sift through text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5:\n",
    "\n",
    "Create a new list from the first three lines of *Christ and Satan* that contains the first letter of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6:\n",
    "\n",
    "Create a new list from the first three lines that contains only words longer than three letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Word Frequencies  <a id='section 3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get started with analyzing the different word frequencies in our text. Run the cell below to open up the text and read in into our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('christ-and-satan.txt', 'r') as f:\n",
    "    christ_and_satan = f.read()\n",
    "\n",
    "print(christ_and_satan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = christ_and_satan.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like a decent start. But we still have verse numbering in there, as well as some punctuation. What if we just want the words?\n",
    "\n",
    "### Challenge 7\n",
    "\n",
    "Get a new `list` of words without numbers or punctuation try using `punctuation` and `digits`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation, digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it feel like time for a list comprehension? It should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Counting <a id='section 4'></a>\n",
    "\n",
    "Python comes with the convenient `Counter` method from the collections library. It returns a dictionary like object that will return the frequency of a particular key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cs_dict = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dict.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Believe it or not, even 1000 years ago \"and\" was still used all the time :) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.DataFrame(cs_dict.most_common()[:10])\n",
    "df = df.set_index(0)\n",
    "df.plot.barh()\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Word')\n",
    "plt.title('Word Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 8:\n",
    "\n",
    "A common measure of lexical diversity for a given text is its *Type-Token Ratio*: the ratio of unique words (type) to number of all words (tokens) in the text. Calculate the Type-Token Ratio for Christ and Satan. ***HINT: Try `set`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ad Hoc Stylometry  <a id='section 5'></a>\n",
    "\n",
    "We can now put together our knowledge of strings, list comprehensions, and plotting frequencies to look at frequency of alliteration letters. Remember: Alliteration is the repetition of a sound at the beginning of two or more words in the same line.\n",
    "\n",
    "Let's start by looking at the first letter of every word in the whole text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_tokens = christ_and_satan.lower().split()\n",
    "first_letters = [x[0] if x[0] not in ['a','e','i','o','u','y'] else 'a' for x in cs_tokens]\n",
    "first_l_dict = Counter(first_letters)\n",
    "print(first_l_dict.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(first_l_dict.most_common()[:10])\n",
    "df = df.set_index(0)\n",
    "df.plot.barh()\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Letter')\n",
    "plt.title('First Letter Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! But we need it within a line, and Thornbury specifically does it for each Fitt. What's a \"Fitt\"? It's a further division in poetry constituted by a group of lines. Luckily this is nicely delimited by double line breaks (`\\n\\n`) in our text. If we had a nice XML corpus, it's likely it would be noted there as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_fitts = christ_and_satan.split('\\n\\n')  # splits up our text based on the location of double line breaks\n",
    "print(cs_fitts[0])  # lets just look at the first element for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to iterate through each fitt. In each fitt, we'll clean the text and get a list of words *for each line*. Then we'll cycle through *each line* and get counts for the first letters of every word. We'll then append the most frequeny letter, ultimately collecting the most frequent first letter for each line. Once we have the most frequent for each line, we'll get the most frequent for that particular fitt. We'll normalize the proportions so we can compare fitts against one another. Then we'll plot the proportion of the *four most common* alliterations for that fitt, as Thornbury does. We'll do this for each fitt, and `show` the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "\n",
    "# iterate through fitts\n",
    "for i in range(len(cs_fitts)):\n",
    "    \n",
    "    # lowercase the string and get the tokens for each line back\n",
    "    fitt_tokens = [l.split() for l in cs_fitts[i].lower().split('\\n')]\n",
    "    \n",
    "    # collect letter of most freq alliteration\n",
    "    most_freq_allit = []\n",
    "    \n",
    "    # cycle through lines\n",
    "    for l in fitt_tokens:\n",
    "        \n",
    "        # get first letter of all words in line\n",
    "        first_letters = [x[0] if x[0] not in ['a','e','i','o','u','y'] else 'a' for x in l]\n",
    "        \n",
    "        # count freq of all first letters\n",
    "        allit_freq = Counter(first_letters).most_common()\n",
    "        try:\n",
    "            # append most freq letter (alliterated letter) to list for all lines\n",
    "            most_freq_allit.append(allit_freq[0][0])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # use Counter to get the most common alliterations\n",
    "    allit_freq = Counter(most_freq_allit).most_common()\n",
    "\n",
    "    # need keys for x axis\n",
    "    common_keys = [x[0] for x in allit_freq]\n",
    "    \n",
    "    # need values for y axes\n",
    "    common_values = [x[1] for x in allit_freq]\n",
    "    \n",
    "    # normalize so we can compare across Fitts despite different number of words\n",
    "    normed_values = [x[1]/sum(common_values) for x in allit_freq]\n",
    "    \n",
    "    # add up to get cumulative alliteration of the four most preferred patterns\n",
    "    cumulative_values = np.cumsum(normed_values)\n",
    "\n",
    "    # add the Fitt to the plot\n",
    "    plt.xticks(range(4), ['1st','2nd','3rd','4th'], rotation='vertical')\n",
    "    plt.plot(cumulative_values[:4], color = plt.cm.bwr(i*.085), lw=3)\n",
    "\n",
    "plt.legend(labels=['Fitt '+str(i+1) for i in range(12)], loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this compare to Thornbury's plot?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](thornbury-4-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tables 4.1-4.3 list the test poems' four most common alliterative patterns\n",
    "by fitt. These patterns are graphed cumulatively in Figures 4.1—4.3, so that\n",
    "the rightmost point in the series indicates the total percentage of the fitt's\n",
    "lines occupied by the four most-favoured patterns. We can see from these\n",
    "figures that, within poems, the correspondence between fitts in overall\n",
    "patterns of variation is relatively close. (p. 164)\n",
    "\n",
    "> What is particularly noteworthy for our purposes is the gap visible between the upper and lower clusters: the average (seen in Figure 4.5) divides Fitts 1-5 plus 8 from Fitts 6,7,\n",
    "and 9—12. These two clusters have significant shared characteristics. The upper\n",
    "set (1-5, 8), which we will call A, has extremely high rates of vowel alliteration\n",
    "and a restricted number of alliterative patterns overall. On average, 65 per cent\n",
    "of the lines of fitts in A alliterate on one of their four preferred letters, while\n",
    "only 53 per cent of those in the lower cluster B do. The average difference\n",
    "between A and B is greater than that between *Christ III*'s most distant outliers,\n",
    "and the gap between *Christ and Satan*'s outliers is more than 20 points. It\n",
    "seems, therefore, that the variation in poetic technique within *Christ and\n",
    "Satan* is substantial enough to - at very least - require explanation. (p. 169)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Super Challenge: Acrostics  <a id='section 6'></a>\n",
    "\n",
    "In poetry, an acrostic is a message created by taking certain letters in a pattern over lines. One 9th century German writer, Otfrid of Weissenburg, was notorius for his early use of acrostics, one instance of which is in the text below: Salomoni episcopo Otfridus. His message can be found by taking the first character of every other line. Print Otfrid's message!\n",
    "\n",
    "Source: http://titus.uni-frankfurt.de/texte/etcs/germ/ahd/otfrid/otfri.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = '''si sálida gimúati      sálomones gúati, \n",
    "     ther bíscof ist nu édiles      kóstinzero sédales; \n",
    "     allo gúati gidúe thio sín,      thio bíscofa er thar hábetin, \n",
    "     ther ínan zi thiu giládota,      in hóubit sinaz zuívalta! \n",
    "     lékza ih therera búachi      iu sentu in suábo richi, \n",
    "     thaz ir irkíaset ubar ál,      oba siu frúma wesan scal; \n",
    "     oba ir hiar fíndet iawiht thés      thaz wírdig ist thes lésannes: \n",
    "     iz iuer húgu irwállo,      wísduames fóllo. \n",
    "     mir wárun thio iuo wízzi      ju ófto filu núzzi, \n",
    "     íueraz wísduam;      thes duan ih míhilan ruam. \n",
    "     ófto irhugg ih múates      thes mánagfalten gúates, \n",
    "     thaz ír mih lértut hárto      íues selbes wórto. \n",
    "     ni thaz míno dohti      giwérkon thaz io móhti, \n",
    "     odo in thén thingon      thio húldi so gilángon; \n",
    "     iz datun gómaheiti,      thio íues selbes gúati, \n",
    "     íueraz giráti,      nales míno dati. \n",
    "     emmizen nu ubar ál      ih druhtin férgon scal, \n",
    "     mit lón er iu iz firgélte      joh sínes selbes wórte; \n",
    "     páradyses résti      gébe iu zi gilústi; \n",
    "     ungilónot ni biléip      ther gotes wízzode kleip. \n",
    "     in hímilriches scóne      so wérde iz iu zi lóne \n",
    "     mit géltes ginúhti,      thaz ír mir datut zúhti. \n",
    "     sínt in thesemo búache,      thes gómo theheiner rúache; \n",
    "     wórtes odo gúates,      thaz lích iu iues múates: \n",
    "     chéret thaz in múate      bi thia zúhti iu zi gúate, \n",
    "     joh zellet tház ana wánc      al in íuweran thanc. \n",
    "     ofto wírdit, oba gúat      thes mannes júngoro giduat, \n",
    "     thaz es líwit thráto      ther zúhtari gúato. \n",
    "     pétrus ther rícho      lono iu es blídlicho, \n",
    "     themo zi rómu druhtin gráp      joh hús inti hóf gap; \n",
    "     óbana fon hímile      sént iu io zi gámane \n",
    "     sálida gimýato      selbo kríst ther gúato! \n",
    "     oba ih irbálden es gidár,      ni scal ih firlázan iz ouh ál, \n",
    "     nub ih ío bi iuih gerno      gináda sina férgo, \n",
    "     thaz hóh er iuo wírdi      mit sínes selbes húldi, \n",
    "     joh iu féstino in thaz múat      thaz sinaz mánagfalta gúat; \n",
    "     firlíhe iu sines ríches,      thes hohen hímilriches, \n",
    "     bi thaz ther gúato hiar io wíaf      joh émmizen zi góte riaf; \n",
    "     rihte íue pédi thara frúa      joh míh gifúage tharazúa, \n",
    "     tház wir unsih fréwen thar      thaz gotes éwiniga jár, \n",
    "     in hímile unsih blíden,      thaz wízi wir bimíden; \n",
    "     joh dúe uns thaz gimúati      thúruh thio síno guati! \n",
    "     dúe uns thaz zi gúate      blídemo múate! \n",
    "     mit héilu er gibóran ward,      ther io thia sálida thar fand, \n",
    "     uuanta es ni brístit furdir      (thes gilóube man mír), \n",
    "     nirfréwe sih mit múatu      íamer thar mit gúatu. \n",
    "     sélbo krist ther guato      firlíhe uns hiar gimúato, \n",
    "     wir íamer fro sin múates      thes éwinigen gúates!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HINT: remember what % does, (maybe) lookup enumerate\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otfrid was more skillful than to settle for the first letter of every other line. What happens if you extract the last letter of the last word of each line, for every other line starting on the second line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HINT: first remove punctuation, tab is represented by \\t\n",
    "from string import punctuation\n",
    "\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Shubham Gupta\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
